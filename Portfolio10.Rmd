---
title: "Portfolio 10"
author: "Martine Lind Jensen"
date: "6/5/2020"
output: word_document
---

# Real World Immitating Task

You are working in a head-hunting agency. Your job is to filter candidates for a top position in a large corporation. During the interviews, the 105 candidates have been subjected to an empathy questionnaire.

```{r}
#Loading packages 

pacman::p_load("tidyverse", "tseries", "psych","GPArotation", "mvtnorm", "polycor","corpcor","GPArotation","pastecs", "corrgram", "e1071")

#Loaded data 
quest <- read.matrix("emp_all_all.csv", header = FALSE, sep = ",", skip = 0)
```

## 1) 
People at your agency disagree on how many interesting components/factors are present in the test, so they ask you, the factor analysis expert, to determine this. Please add your argument for the number you end on.

```{r}
#Checking whether our data is highly correlated and if it makes sense to make an factor analysis/PCA
cortest.bartlett(quest) #It is correlated 

#Running principal component analysis 
pca1 <- princomp(quest)

#Looking at screeplot, it seems like 4 factors would be a good number of factors
screeplot(pca1, type ="line", main = "screeplot")

#Running a parallel test (Horn's) it confirmes that 4 factors are a good number
parallel <- fa.parallel(quest, fm ="minres", fa ="fa", sim = FALSE)

#Running a factor analysis to get a more interpretable output with 4 factors and with a oblique rotation, because Andy Fields says that, oblique transformations are useful when the variables are highly correlated and tests for the same thing (empathy) and getting the scores
fa <- factanal(quest, 4, rotation = "oblimin", scores = "Bartlett")

#Setting the cutoff to 0.3 to see which loadings are the highest, and making the output easy to interpret
print(fa, digits = 3, cutoff = 0.3, sort = FALSE)
```

#### After runing a principle component analysis and making a screeplot we found that four components seems to explain most of the variance in the data. To support this we made a Horn's parallel test, that also showed that four factors would be a reasonable amount of factors to explain the data. After that we ran a factorial analysis, to get a more interpretable output. And this is the analysis we are working with.

## 2) 
In order to short-list candidates for the position, your job is to find the highest and lowest scoring candidate on each factor.

```{r}

#Which is lowest on each factor
which.min(fa$scores[,1])
which.min(fa$scores[,2])
which.min(fa$scores[,3])
which.min(fa$scores[,4])

#Which is highest on each factor 
which.max(fa$scores[,1])
which.max(fa$scores[,2])
which.max(fa$scores[,3])
which.max(fa$scores[,4])

#Making dataframe for pretty plots
f1<-fa$scores[,1]
f2<-fa$scores[,2]
f3<-fa$scores[,3]
f4<-fa$scores[,4]

#Adding participant numbers
par <- c(1:105)
 
#Making dataframe for pretty plots
scores<-data.frame(f1,f2,f3,f4,par)

#Making participant number as character for pretty plots
scores$par <- as.character(scores$par)

#Pretty plot number 1, showing factor 1
p1 <- ggplot(scores,aes(par, f1, label = par))+ 
  geom_point(size=2)+
  geom_text(hjust = 1.5, vjus =1)

#Pretty plot number 2, showing factor 1 and factor 2 
p2 <- ggplot(scores,aes(f1,f2, label = par))+ 
  geom_point(size=2)+
  geom_text(hjust = 1.5)
p2

#Pretty plot number 3, showing factor 3 and factor 4 
p3 <- ggplot(scores,aes(f3, f4, label = par))+ 
  geom_point(size=2)+
  geom_text(hjust = 1.5)
p3

```


#### We calculated that partcipant 34 scored the lowest on factor 1, 3, and 4, while particpant 83 scored the lowest on factor 2. In the other end of the scale we have partcipant number 83 who scored the highest on factor 1 and partcipant 12 scored the highest on factor 2, partcipant 53 on factor 3 and participant 102 on factor 4. 

#### The plots p2 and p3 shows how the partcipants are valued on each factor. 

## 3) 
Your boss asks you what you think of his new empathy test (The physical empathy test). Does it really measure anything that the old scales cannot capture?

```{r}
#Showing the 
print(fa, digits = 3, cutoff = 0.3, sort = FALSE)
```

#### Looking at the loadings it seems like the questions in the physical empathy test covers the same nuances as some questions from BEES and IRI, and could therefore be removed from the questionaire without disrupting the results. The physical empathy tests only loads on the first factor and one of the dimensions in the IRI already covers that quite extensively.  

## 4) 
You also want to impress your boss with a couple of illustrative plots.

```{r}
library(e1071)

#Hamming plot, showing how alike the participants are in their answers 
#This plot is very impressive on the color value - but might not be super informative - which is why we do the next plot as well.
quest_hamming <- hamming.distance(quest)
image(scale(quest_hamming))

#Plot showing how far each partcipant are from the mean,
plot(colMeans(quest_hamming), type = "h")

```

#### The plots show that partcipant 34 is very different from the rest of the partcipants, which falls perfectly in line with the partcipants very low scores on 3 out of the 4 factors evaluating empathy. The plots show that this participant is out-standing and is perfectly suited to be Mikkels apathetic assitant. As they say - opposites attract! 

